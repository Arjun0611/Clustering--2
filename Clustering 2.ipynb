{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fda3d4-156f-4a50-b4e7-272bf336afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.\n",
    "\n",
    "# Hierarchical Clustering: \n",
    "    # A clustering algorithm that builds a hierarchy of clusters, either agglomerative or divisive.\n",
    "    # Agglomerative: Starts with individual data points and merges them hierarchically.\n",
    "    # Divisive: Begins with one cluster and recursively splits it into smaller clusters.\n",
    "# Differences from other clustering techniques:\n",
    "    # Hierarchy: Creates a tree-like structure of clusters.\n",
    "    # No Fixed K: Does not require a predefined number of clusters.\n",
    "    # Nested Structures: Captures nested relationships within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bff6f7c5-b893-426c-b558-cf93313f0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.\n",
    "\n",
    "# Agglomerative Hierarchical Clustering:\n",
    "    # Approach: Starts with individual data points and merges them hierarchically.\n",
    "    # Process: Iteratively merges the most similar clusters until a single cluster is formed.\n",
    "    # Hierarchy: Creates a tree-like structure, often represented as a dendrogram.\n",
    "# Divisive Hierarchical Clustering:\n",
    "    # Approach: Begins with one supercluster and recursively splits it into smaller clusters.\n",
    "    # Process: Repeatedly divides clusters into subclusters until individual data points are reached.\n",
    "    # Hierarchy: Forms a tree structure, representing the division of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1ee297f-1871-49b4-bc7c-de79c4d04dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.\n",
    "\n",
    "# Method: Measure the dissimilarity or distance between two clusters.\n",
    "# Common Metrics:\n",
    "    # Single Linkage: Minimum distance between any two points in the two clusters.\n",
    "    # Complete Linkage: Maximum distance between any two points in the two clusters.\n",
    "    # Average Linkage: Average distance between all pairs of points in the two clusters.\n",
    "    # Centroid Linkage: Distance between the centroids of the two clusters.\n",
    "    # Ward's Method: Minimizes the increase in variance after merging clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51411af4-5fd7-4dee-95a7-1720efaa025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4.\n",
    "\n",
    "# Dendrogram Analysis:\n",
    "    # Approach: Visualize the dendrogram and identify the point where merging clusters results in diminishing returns.\n",
    "    # Optimal K: The number of clusters at the chosen cutoff point.\n",
    "# Silhouette Score:\n",
    "    # Approach: Measure how well-separated clusters are using silhouette coefficients.\n",
    "    # Optimal K: Choose K with the highest average silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a85cfa12-aadf-4e4b-913f-538a1eca766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5.\n",
    "\n",
    "# Dendrograms: Tree-like diagrams illustrating the hierarchical relationships b/w clusters in hierarchical clustering.\n",
    "\n",
    "# Usefulness:\n",
    "    # Hierarchy Visualization: Display how clusters merge or split at each level.\n",
    "    # Cutting Threshold: Identify optimal number of clusters by choosing a cutting threshold.\n",
    "    # Cluster Distances: Show the dissimilarity distances between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebc59bfb-ac7f-4fe2-9ae7-6335bacd2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6.\n",
    "\n",
    "# Hierarchical Clustering for Numerical Data:\n",
    "    # Distance Metrics: Use Euclidean distance, Manhattan distance, or correlation-based measures.\n",
    "# Hierarchical Clustering for Categorical Data:\n",
    "    # Distance Metrics: Jaccard distance, Hamming distance, or other metrics suitable for categorical variables.\n",
    "# Mixed Data Types:\n",
    "    # Approach: Use appropriate distance metrics for each data type, or employ methods that can handle mixed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e28b23b5-b91d-415f-9376-608b33c03102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7.\n",
    "\n",
    "# Approach to identify outliers or anomalies in the data using hierarchical clustering?\n",
    "\n",
    "# Dendrogram Analysis: Examine branches with small clusters or individual data points.\n",
    "# Outliers Detection: Points with their own branches or separate small clusters may indicate outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732fe59-e682-48bb-a167-6b1b09e13ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
